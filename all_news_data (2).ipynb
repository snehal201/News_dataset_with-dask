{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all news data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRej1ZXV_ImC"
      },
      "source": [
        "!wget -q !wget https://www.dropbox.com/s/cn2utnr5ipathhh/all-the-news-2-1.zip?dl=0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjLfnrvHqcrY",
        "outputId": "134a3749-6470-42aa-e970-8818695b8f83"
      },
      "source": [
        "! unzip /content/all-the-news-2-1.zip?dl=0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/all-the-news-2-1.zip?dl=0\n",
            "  inflating: all-the-news-2-1.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2gi_qJgWFAP",
        "outputId": "996df96a-182d-4859-97ef-b388d20a0be9"
      },
      "source": [
        " pip install dask[dataframe]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2018.9)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n",
            "Installing collected packages: locket, partd, fsspec\n",
            "Successfully installed fsspec-2021.7.0 locket-0.2.1 partd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC7FIHkCwRTs"
      },
      "source": [
        "###importing necessary library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsjm_K-MWmZK"
      },
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dask.dataframe as dd\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from itertools import filterfalse\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_ka1XhKNdW"
      },
      "source": [
        "contractions_dict={\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I'm'a\": \"I am about to\",\n",
        "    \"I'm'o\": \"I am going to\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"Whatcha\": \"What are you\",\n",
        "    \"amn't\": \"am not\",\n",
        "    \"ain't\": \"are not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"daren't\": \"dare not\",\n",
        "    \"daresn't\": \"dare not\",\n",
        "    \"dasn't\": \"dare not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"didn’t\": \"did not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"don’t\": \"do not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"e'er\": \"ever\",\n",
        "    \"everyone's\": \"everyone is\",\n",
        "    \"finna\": \"fixing to\",\n",
        "    \"gimme\": \"give me\",\n",
        "    \"gon't\": \"go not\",\n",
        "    \"gonna\": \"going to\",\n",
        "    \"gotta\": \"got to\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he've\": \"he have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"here's\": \"here is\",\n",
        "    \"how're\": \"how are\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"'tis\": \"it is\",\n",
        "    \"'twas\": \"it was\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"kinda\": \"kind of\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"luv\": \"love\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"may've\": \"may have\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"ne'er\": \"never\",\n",
        "    \"o'\": \"of\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"ol'\": \"old\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"o'er\": \"over\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shalln't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so is\",\n",
        "    \"somebody's\": \"somebody is\",\n",
        "    \"someone's\": \"someone is\",\n",
        "    \"something's\": \"something is\",\n",
        "    \"sux\": \"sucks\",\n",
        "    \"that're\": \"that are\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"that'll\": \"that will\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"em\": \"them\",\n",
        "    \"there're\": \"there are\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"there'll\": \"there will\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"these're\": \"these are\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"this's\": \"this is\",\n",
        "    \"those're\": \"those are\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wanna\": \"want to\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what'd\": \"what did\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"where're\": \"where are\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"which's\": \"which is\",\n",
        "    \"who're\": \"who are\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who'd\": \"who would\",\n",
        "    \"who'd've\": \"who would have\",\n",
        "    \"why're\": \"why are\",\n",
        "    \"why'd\": \"why did\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"you'll've\": \"you shall have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\"\n",
        " }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUMGmAjZwaZU"
      },
      "source": [
        "###Read data with dask Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "zjlCTKwa_JPM",
        "outputId": "8d096a4f-b6dd-49ec-c206-d06d73a6426f"
      },
      "source": [
        "data =dd.read_csv('/content/all-the-news-2-1.csv',error_bad_lines=False,engine='python',encoding=\"utf8\"\n",
        "                  ,dtype={'Unnamed: 0':'object','Unnamed: 0.1':'object','day':'object','year':'object','month':'object'})\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>author</th>\n",
              "      <th>title</th>\n",
              "      <th>article</th>\n",
              "      <th>url</th>\n",
              "      <th>section</th>\n",
              "      <th>publication</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-12-09 18:31:00</td>\n",
              "      <td>2016</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9</td>\n",
              "      <td>Lee Drutman</td>\n",
              "      <td>We should take concerns about the health of li...</td>\n",
              "      <td>This post is part of Polyarchy, an independent...</td>\n",
              "      <td>https://www.vox.com/polyarchy/2016/12/9/138983...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Vox</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-10-07 21:26:46</td>\n",
              "      <td>2016</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7</td>\n",
              "      <td>Scott Davis</td>\n",
              "      <td>Colts GM Ryan Grigson says Andrew Luck's contr...</td>\n",
              "      <td>The Indianapolis Colts made Andrew Luck the h...</td>\n",
              "      <td>https://www.businessinsider.com/colts-gm-ryan-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Business Insider</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-01-26 00:00:00</td>\n",
              "      <td>2018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Trump denies report he ordered Mueller fired</td>\n",
              "      <td>DAVOS, Switzerland (Reuters) - U.S. President ...</td>\n",
              "      <td>https://www.reuters.com/article/us-davos-meeti...</td>\n",
              "      <td>Davos</td>\n",
              "      <td>Reuters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2019-06-27 00:00:00</td>\n",
              "      <td>2019</td>\n",
              "      <td>6.0</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>France's Sarkozy reveals his 'Passions' but in...</td>\n",
              "      <td>PARIS (Reuters) - Former French president Nico...</td>\n",
              "      <td>https://www.reuters.com/article/france-politic...</td>\n",
              "      <td>World News</td>\n",
              "      <td>Reuters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2016-01-27 00:00:00</td>\n",
              "      <td>2016</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paris Hilton: Woman In Black For Uncle Monty's...</td>\n",
              "      <td>Paris Hilton arrived at LAX Wednesday dressed ...</td>\n",
              "      <td>https://www.tmz.com/2016/01/27/paris-hilton-mo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TMZ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0 Unnamed: 0.1  ...     section       publication\n",
              "0          0            0  ...         NaN               Vox\n",
              "1          1            1  ...         NaN  Business Insider\n",
              "2          2            2  ...       Davos           Reuters\n",
              "3          3            3  ...  World News           Reuters\n",
              "4          4            4  ...         NaN               TMZ\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV3YhrNGwfjE"
      },
      "source": [
        "###Drop unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og0FsEW_J1r9"
      },
      "source": [
        "df=data.drop(['Unnamed: 0','Unnamed: 0.1','url','section','author','day','month','date','year','publication'],axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_VR1FsPKD8k",
        "outputId": "a4a298ae-b143-4fc9-b2bd-b5a3353d9c0d"
      },
      "source": [
        "data=df.fillna(0)  ##Fill na with zero\n",
        "data.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title      object\n",
              "article    object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXctw346wu6b"
      },
      "source": [
        "###combining the title and article column text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkTfOD11JCP"
      },
      "source": [
        "columns=data.columns\n",
        "data['text']=data[columns].apply(func=(lambda row: ' '.join(row.values.astype(str))) ,axis=1,meta=('str'))\n",
        "data=data.drop(columns,axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rslQrKFpw3gC"
      },
      "source": [
        "##**text preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ_pF0L96vm6",
        "outputId": "e2fc1a69-4da1-4852-fd98-b0b8c5681916"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StfDLdhZ2n-M",
        "outputId": "3442410f-fe31-40f2-ae24-971942d4ef64"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljLOmLDMKd7f"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: word_tokenize(x),meta=('text'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oyCVpSaxAgrE",
        "outputId": "0756efbc-492d-4ea8-8559-ffcee2143632"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[We, should, take, concerns, about, the, healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Colts, GM, Ryan, Grigson, says, Andrew, Luck,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Trump, denies, report, he, ordered, Mueller, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[France, 's, Sarkozy, reveals, his, 'Passions,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Paris, Hilton, :, Woman, In, Black, For, Uncl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [We, should, take, concerns, about, the, healt...\n",
              "1  [Colts, GM, Ryan, Grigson, says, Andrew, Luck,...\n",
              "2  [Trump, denies, report, he, ordered, Mueller, ...\n",
              "3  [France, 's, Sarkozy, reveals, his, 'Passions,...\n",
              "4  [Paris, Hilton, :, Woman, In, Black, For, Uncl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COHY6VtFKlVn"
      },
      "source": [
        "def normalize_tokens(list_of_tokens):\n",
        "    return map(lambda x: x.lower(),list_of_tokens)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0vK_wQKr_v"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: normalize_tokens(x),meta=('text'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avwFYa9I1sx_"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-643FTrnBcSd",
        "outputId": "a1d8b19f-805f-4aa7-b232-256a2698b119"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[france, 's, sarkozy, reveals, his, 'passions,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, hilton, :, woman, in, black, for, uncl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [we, should, take, concerns, about, the, healt...\n",
              "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
              "2  [trump, denies, report, he, ordered, mueller, ...\n",
              "3  [france, 's, sarkozy, reveals, his, 'passions,...\n",
              "4  [paris, hilton, :, woman, in, black, for, uncl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHoGu90T2oCG",
        "outputId": "74bafa12-063e-4e2a-ff02-d5e88bba91df"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy1uxt8Knu5C"
      },
      "source": [
        "def contracted_word_expansion(token):\n",
        "    if token in contractions_dict.keys():\n",
        "        return contractions_dict[token]\n",
        "    else:\n",
        "        return token"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mNc_TkCny7X"
      },
      "source": [
        "def contractions_expansion(list_of_tokens):\n",
        "    return map(contracted_word_expansion,list_of_tokens)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTeYtITgn1Pd"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: contractions_expansion(x),meta=('text'))\n",
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XY2xxrFoBe_o",
        "outputId": "84992829-c971-4925-a221-5dc9d6326e04"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[france, 's, sarkozy, reveals, his, 'passions,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, hilton, :, woman, in, black, for, uncl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [we, should, take, concerns, about, the, healt...\n",
              "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
              "2  [trump, denies, report, he, ordered, mueller, ...\n",
              "3  [france, 's, sarkozy, reveals, his, 'passions,...\n",
              "4  [paris, hilton, :, woman, in, black, for, uncl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPfvlTbSotrY"
      },
      "source": [
        "regex = r'^@[a-zA-z0-9]|^#[a-zA-Z0-9]|\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*|\\W+|\\d+|<(\"[^\"]*\"|\\'[^\\']*\\'|[^\\'\">])*>|_+|[^\\u0000-\\u007f]+'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBz0YtSFn5X5"
      },
      "source": [
        "def waste_word_or_not(token):\n",
        "    return re.search(regex,token)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zVnK-DJn-uG"
      },
      "source": [
        "def filter_waste_words(list_of_tokens):\n",
        "    return filterfalse(waste_word_or_not,list_of_tokens)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuQVs33OoA25"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: filter_waste_words(x),meta=('text'))\n",
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PEIG_cGdBhSx",
        "outputId": "34b3e858-5992-4405-f9cb-b9b377dc8db1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[france, sarkozy, reveals, his, but, insists, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, hilton, woman, in, black, for, uncle, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [we, should, take, concerns, about, the, healt...\n",
              "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
              "2  [trump, denies, report, he, ordered, mueller, ...\n",
              "3  [france, sarkozy, reveals, his, but, insists, ...\n",
              "4  [paris, hilton, woman, in, black, for, uncle, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuOY5ik7oKxu"
      },
      "source": [
        "def split(list_of_tokens):\n",
        "    return map(lambda x: re.split(regex,x)[0],list_of_tokens)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zZzR0yCoEsU"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: split(x),meta=('text'))\n",
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Mzd1ltDYBkFS",
        "outputId": "688843ba-77d1-4fb6-bea5-c57d15caf3bf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[france, sarkozy, reveals, his, but, insists, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, hilton, woman, in, black, for, uncle, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [we, should, take, concerns, about, the, healt...\n",
              "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
              "2  [trump, denies, report, he, ordered, mueller, ...\n",
              "3  [france, sarkozy, reveals, his, but, insists, ...\n",
              "4  [paris, hilton, woman, in, black, for, uncle, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3i6em57DaYX",
        "outputId": "5188007f-047a-4038-a51f-29f54f51d942"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uv9OtMNRx4I"
      },
      "source": [
        "en_stop_words = list(set(stopwords.words('english')).union(set(STOP_WORDS)))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixrcym0Q2f3R"
      },
      "source": [
        "def is_stopword(token):\n",
        "    return not(token in en_stop_words or re.search(r'\\b\\w\\b|[^\\u0000-\\u007f]+|_+|\\W+',token))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pVoBUE42gLA"
      },
      "source": [
        "def stopwords_removal(list_of_tokens):\n",
        "    return filter(is_stopword,list_of_tokens)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhhwpzpi2i2X"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: stopwords_removal(x),meta=('text'))\n",
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MpGhLk6YBmhQ",
        "outputId": "0e3a1a1d-d66c-47ca-d2cf-add5916cb1e2"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[concerns, health, liberal, democracy, serious...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trump, denies, report, ordered, mueller, fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[france, sarkozy, reveals, insists, cards, par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, hilton, woman, black, uncle, monty, fu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [concerns, health, liberal, democracy, serious...\n",
              "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
              "2  [trump, denies, report, ordered, mueller, fire...\n",
              "3  [france, sarkozy, reveals, insists, cards, par...\n",
              "4  [paris, hilton, woman, black, uncle, monty, fu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu4kZmcV2oPN"
      },
      "source": [
        "def get_wnet_pos_tag(treebank_tag):\n",
        "    if treebank_tag[1].startswith('J'):\n",
        "        return (treebank_tag[0],wordnet.ADJ)\n",
        "    elif treebank_tag[1].startswith('V'):\n",
        "        return (treebank_tag[0],wordnet.VERB)\n",
        "    elif treebank_tag[1].startswith('N'):\n",
        "        return (treebank_tag[0],wordnet.NOUN)\n",
        "    elif treebank_tag[1].startswith('R'):\n",
        "        return (treebank_tag[0],wordnet.ADV)\n",
        "    else:\n",
        "        (treebank_tag[0],wordnet.NOUN)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuScd8ISDI6u",
        "outputId": "0dd621d4-495e-4c10-bfb2-38d80f3699e2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN0tnQsrDNuM",
        "outputId": "65742ca7-526d-4bdb-8403-4f7d00fb4180"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7pYgens2n7f"
      },
      "source": [
        "def get_pos_tag(list_of_tokens):\n",
        "    return map(get_wnet_pos_tag,pos_tag(list_of_tokens))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh9sACeyIZ1d",
        "outputId": "4ac883d3-d043-42d8-eb80-3507f965ec30"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBvtkQY2n5I"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: get_pos_tag(x),meta=('text'))\n",
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FEgOIbbaBqbJ",
        "outputId": "01985843-c305-4f46-d02a-3d4f1c974260"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(concerns, n), (health, n), (liberal, a), (de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(colts, n), (gm, v), (ryan, a), (grigson, n),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(trump, n), (denies, n), (report, n), (ordere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(france, n), (sarkozy, n), (reveals, n), (ins...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(paris, a), (hilton, n), (woman, n), (black, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [(concerns, n), (health, n), (liberal, a), (de...\n",
              "1  [(colts, n), (gm, v), (ryan, a), (grigson, n),...\n",
              "2  [(trump, n), (denies, n), (report, n), (ordere...\n",
              "3  [(france, n), (sarkozy, n), (reveals, n), (ins...\n",
              "4  [(paris, a), (hilton, n), (woman, n), (black, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bo-ewlv233g"
      },
      "source": [
        " lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XMm3TVv23ze"
      },
      "source": [
        "def token_lemmatization(token_pos_tuple):\n",
        "    if token_pos_tuple == None:\n",
        "        return \"\"\n",
        "    else:\n",
        "        return lemmatizer.lemmatize(word=token_pos_tuple[0],pos=token_pos_tuple[1])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6odmjRL23w7"
      },
      "source": [
        "def lemmatization(list_of_tokens):\n",
        "    if len(list_of_tokens) > 0:\n",
        "        return map(lambda x: token_lemmatization(x),list_of_tokens)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3L1j3yB23uP"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: lemmatization(x),meta=('text'))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEU8Deii23rn"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wzXAHV9MRxT3",
        "outputId": "267bc96f-9fb7-4213-9f48-e5c172f0dd6c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[concern, health, liberal, democracy, seriousl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colt, gm, ryan, grigson, say, , luck, contrac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trump, denies, report, order, mueller, fire, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[france, sarkozy, reveals, insist, card, paris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, hilton, woman, black, uncle, monty, fu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [concern, health, liberal, democracy, seriousl...\n",
              "1  [colt, gm, ryan, grigson, say, , luck, contrac...\n",
              "2  [trump, denies, report, order, mueller, fire, ...\n",
              "3  [france, sarkozy, reveals, insist, card, paris...\n",
              "4  [paris, hilton, woman, black, uncle, monty, fu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k40gAljxBEn"
      },
      "source": [
        "##**most frequent word for each row**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qStkApyRrSfP"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad0KWfobVNLB"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: [k for k, v in Counter(x).most_common(50)],meta=('text'))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HupoQyUOfOPE",
        "outputId": "5276fbfc-3a9e-4f5a-bd77-d3e6cb312d52"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[democracy, heart, attack, seriously, foa, mou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[colt, , luck, defense, contract, team, grigso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[report, trump, order, fake, news, mueller, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sarkozy, return, party, president, politics, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[paris, monty, hilton, uncle, funeral, brinson...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [democracy, heart, attack, seriously, foa, mou...\n",
              "1  [colt, , luck, defense, contract, team, grigso...\n",
              "2  [report, trump, order, fake, news, mueller, fi...\n",
              "3  [sarkozy, return, party, president, politics, ...\n",
              "4  [paris, monty, hilton, uncle, funeral, brinson..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}